{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: Sameer's Angels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members:  \n",
    "Patrick Jose (20947156)  \n",
    "Christian Poon (79555434)  \n",
    "Tri Hoang (15681623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "from __future__ import division # For python 2.*\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"data/X_train.txt\",delimiter=None)\n",
    "Y = np.genfromtxt(\"data/Y_train.txt\",delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "\n",
    "Xtr,Xva,Ytr,Yva = ml.splitData(X,Y)\n",
    "Xtr, Ytr = ml.shuffleData(Xtr, Ytr)\n",
    "\n",
    "Xte = np.genfromtxt('data/X_test.txt',delimiter=None)\n",
    "\n",
    "#XtrS, params = ml.rescale(Xtr) # Normalize the features\n",
    "#XvS, _ = ml.rescale(Xva, params) # Normalize the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_bags = 20\n",
    "bags = []   # self.learners\n",
    "for l in range(n_bags):\n",
    "    # Each boosted data is the size of the original data. \n",
    "    Xi, Yi = ml.bootstrapData(Xtr, Ytr, X.shape[0] // 2)\n",
    "\n",
    "    # Train the model on that draw\n",
    "    tree = ml.dtree.treeClassify(Xi, Yi, minParent=2**6, maxDepth=25, nFeatures=6)\n",
    "    bags.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "      Train AUC: 0.7489\n",
      " Validation AUC: 0.6680\n",
      "1\n",
      "      Train AUC: 0.7580\n",
      " Validation AUC: 0.6743\n",
      "2\n",
      "      Train AUC: 0.7587\n",
      " Validation AUC: 0.6777\n",
      "3\n",
      "      Train AUC: 0.7525\n",
      " Validation AUC: 0.6674\n",
      "4\n",
      "      Train AUC: 0.7541\n",
      " Validation AUC: 0.6729\n",
      "5\n",
      "      Train AUC: 0.7516\n",
      " Validation AUC: 0.6703\n",
      "6\n",
      "      Train AUC: 0.7528\n",
      " Validation AUC: 0.6719\n",
      "7\n",
      "      Train AUC: 0.7569\n",
      " Validation AUC: 0.6737\n",
      "8\n",
      "      Train AUC: 0.7565\n",
      " Validation AUC: 0.6749\n",
      "9\n",
      "      Train AUC: 0.7510\n",
      " Validation AUC: 0.6730\n",
      "10\n",
      "      Train AUC: 0.7524\n",
      " Validation AUC: 0.6754\n",
      "11\n",
      "      Train AUC: 0.7578\n",
      " Validation AUC: 0.6780\n",
      "12\n",
      "      Train AUC: 0.7590\n",
      " Validation AUC: 0.6778\n",
      "13\n",
      "      Train AUC: 0.7552\n",
      " Validation AUC: 0.6743\n",
      "14\n",
      "      Train AUC: 0.7512\n",
      " Validation AUC: 0.6719\n",
      "15\n",
      "      Train AUC: 0.7506\n",
      " Validation AUC: 0.6657\n",
      "16\n",
      "      Train AUC: 0.7593\n",
      " Validation AUC: 0.6819\n",
      "17\n",
      "      Train AUC: 0.7626\n",
      " Validation AUC: 0.6804\n",
      "18\n",
      "      Train AUC: 0.7591\n",
      " Validation AUC: 0.6755\n",
      "19\n",
      "      Train AUC: 0.7579\n",
      " Validation AUC: 0.6725\n"
     ]
    }
   ],
   "source": [
    "for l in range(n_bags):\n",
    "    print(l)\n",
    "    print(\"{0:>15}: {1:.4f}\".format('Train AUC', bags[l].auc(Xtr, Ytr)))\n",
    "    print(\"{0:>15}: {1:.4f}\".format('Validation AUC', bags[l].auc(Xva, Yva)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaggedTree(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        \"\"\"Constructs a BaggedTree class with a set of learners. \"\"\"\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self, X):\n",
    "        \"\"\"Predicts the probabilities with each bagged learner and average over the results. \"\"\"\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predictSoft(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bt = BaggedTree(bags)\n",
    "bt.classes = np.unique(Y)\n",
    "\n",
    "probs = bt.predictSoft(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25345816  0.74654184]\n",
      " [ 0.56905768  0.43094232]\n",
      " [ 0.80761937  0.19238063]\n",
      " ..., \n",
      " [ 0.77019973  0.22980027]\n",
      " [ 0.77559865  0.22440135]\n",
      " [ 0.77336018  0.22663982]]\n",
      "      Train AUC: 0.8692\n",
      " Validation AUC: 0.7592\n"
     ]
    }
   ],
   "source": [
    "print(probs)\n",
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC', bt.auc(Xtr, Ytr)))\n",
    "print(\"{0:>15}: {1:.4f}\".format('Validation AUC', bt.auc(Xva, Yva)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier\n",
    "\n",
    "Used polynomial feature expansion to transform the dataset from 14 features to 119 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtrSP = ml.transforms.fpoly(XtrS, 2, False)\n",
    "\n",
    "# Rescale the data matrix so that the features have similar ranges / variance\n",
    "XtrSP, XtrSP_params = ml.transforms.rescale(XtrSP)\n",
    "# \"params\" returns the transformation parameters (shift & scale)\n",
    "\n",
    "XvSP = ml.transforms.fpoly(XvS, 2, False)\n",
    "\n",
    "XvSP, XvSP_params = ml.transforms.rescale(XvSP)\n",
    "\n",
    "XteP = ml.transforms.fpoly(Xte, 2, False)\n",
    "\n",
    "XteP, XteP_params = ml.transforms.rescale(XteP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 119)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrSP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear = ml.linearC.linearClassify()\n",
    "\n",
    "linear.train(XtrSP, Ytr, reg=0.1, initStep=0.01, stopTol=1e-6, stopIter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65037406  0.34962594]\n",
      " [ 0.5861603   0.4138397 ]\n",
      " [ 0.64398876  0.35601124]\n",
      " ..., \n",
      " [ 0.68422899  0.31577101]\n",
      " [ 0.64840227  0.35159773]\n",
      " [ 0.66142157  0.33857843]]\n",
      "      Train AUC: 0.6586\n",
      " Validation AUC: 0.6541\n"
     ]
    }
   ],
   "source": [
    "probs = linear.predictSoft(XteP)\n",
    "print(probs)\n",
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC', linear.auc(XtrSP, Ytr)))\n",
    "print(\"{0:>15}: {1:.4f}\".format('Validation AUC', linear.auc(XvSP, Yva)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(Xtr, Ytr)\n",
    "\n",
    "ada_x_train = clf.predict(Xtr)\n",
    "ada_x_val = clf.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49013187  0.50986813]\n",
      " [ 0.72193886  0.27806114]\n",
      " [ 0.72193886  0.27806114]\n",
      " ..., \n",
      " [ 0.49013187  0.50986813]\n",
      " [ 0.49013187  0.50986813]\n",
      " [ 0.72193886  0.27806114]]\n",
      "[[ 0.48299413  0.51700587]\n",
      " [ 0.63932589  0.36067411]\n",
      " [ 0.60557248  0.39442752]\n",
      " ..., \n",
      " [ 0.48299413  0.51700587]\n",
      " [ 0.48299413  0.51700587]\n",
      " [ 0.60557248  0.39442752]]\n",
      "[[ 0.4854282   0.5145718 ]\n",
      " [ 0.59114219  0.40885781]\n",
      " [ 0.56780193  0.43219807]\n",
      " ..., \n",
      " [ 0.4854282   0.5145718 ]\n",
      " [ 0.4854282   0.5145718 ]\n",
      " [ 0.56780193  0.43219807]]\n",
      "[[ 0.47782912  0.52217088]\n",
      " [ 0.57544402  0.42455598]\n",
      " [ 0.53982858  0.46017142]\n",
      " ..., \n",
      " [ 0.47782912  0.52217088]\n",
      " [ 0.49596345  0.50403655]\n",
      " [ 0.55780235  0.44219765]]\n",
      "[[ 0.48474681  0.51525319]\n",
      " [ 0.56297384  0.43702616]\n",
      " [ 0.53436666  0.46563334]\n",
      " ..., \n",
      " [ 0.48474681  0.51525319]\n",
      " [ 0.49926111  0.50073889]\n",
      " [ 0.52782732  0.47217268]]\n",
      "[[ 0.47806717  0.52193283]\n",
      " [ 0.55601543  0.44398457]\n",
      " [ 0.53213296  0.46786704]\n",
      " ..., \n",
      " [ 0.47806717  0.52193283]\n",
      " [ 0.49015355  0.50984645]\n",
      " [ 0.52668124  0.47331876]]\n",
      "[[ 0.47962173  0.52037827]\n",
      " [ 0.54650291  0.45349709]\n",
      " [ 0.52597921  0.47402079]\n",
      " ..., \n",
      " [ 0.47962173  0.52037827]\n",
      " [ 0.48998251  0.51001749]\n",
      " [ 0.52130056  0.47869944]]\n",
      "[[ 0.48354474  0.51645526]\n",
      " [ 0.54208782  0.45791218]\n",
      " [ 0.52411324  0.47588676]\n",
      " ..., \n",
      " [ 0.48354474  0.51645526]\n",
      " [ 0.49261373  0.50738627]\n",
      " [ 0.52001824  0.47998176]]\n",
      "[[ 0.49047233  0.50952767]\n",
      " [ 0.53520101  0.46479899]\n",
      " [ 0.5192004   0.4807996 ]\n",
      " ..., \n",
      " [ 0.49047233  0.50952767]\n",
      " [ 0.49853731  0.50146269]\n",
      " [ 0.51555769  0.48444231]]\n",
      "[[ 0.49237005  0.50762995]\n",
      " [ 0.53263236  0.46736764]\n",
      " [ 0.51822618  0.48177382]\n",
      " ..., \n",
      " [ 0.49237005  0.50762995]\n",
      " [ 0.493401    0.506599  ]\n",
      " [ 0.51494739  0.48505261]]\n",
      "[[ 0.49290069  0.50709931]\n",
      " [ 0.52951073  0.47048927]\n",
      " [ 0.51640777  0.48359223]\n",
      " ..., \n",
      " [ 0.49290069  0.50709931]\n",
      " [ 0.49383793  0.50616207]\n",
      " [ 0.51342642  0.48657358]]\n",
      "[[ 0.49258309  0.50741691]\n",
      " [ 0.52614979  0.47385021]\n",
      " [ 0.51413278  0.48586722]\n",
      " ..., \n",
      " [ 0.49258309  0.50741691]\n",
      " [ 0.49344222  0.50655778]\n",
      " [ 0.51139922  0.48860078]]\n",
      "[[ 0.49333281  0.50666719]\n",
      " [ 0.5243204   0.4756796 ]\n",
      " [ 0.51322533  0.48677467]\n",
      " ..., \n",
      " [ 0.49333281  0.50666719]\n",
      " [ 0.49412588  0.50587412]\n",
      " [ 0.51070184  0.48929816]]\n",
      "[[ 0.49396022  0.50603978]\n",
      " [ 0.52273662  0.47726338]\n",
      " [ 0.51243222  0.48756778]\n",
      " ..., \n",
      " [ 0.49396022  0.50603978]\n",
      " [ 0.49469666  0.50530334]\n",
      " [ 0.51008883  0.48991117]]\n",
      "[[ 0.49412764  0.50587236]\n",
      " [ 0.52098793  0.47901207]\n",
      " [ 0.51136861  0.48863139]\n",
      " ..., \n",
      " [ 0.49412764  0.50587236]\n",
      " [ 0.49481499  0.50518501]\n",
      " [ 0.50918126  0.49081874]]\n",
      "[[ 0.49496194  0.50503806]\n",
      " [ 0.5201442   0.4798558 ]\n",
      " [ 0.51112543  0.48887457]\n",
      " ..., \n",
      " [ 0.49275575  0.50724425]\n",
      " [ 0.4934001   0.5065999 ]\n",
      " [ 0.50907476  0.49092524]]\n",
      "[[ 0.49664284  0.50335716]\n",
      " [ 0.51802128  0.48197872]\n",
      " [ 0.50953114  0.49046886]\n",
      " ..., \n",
      " [ 0.49456628  0.50543372]\n",
      " [ 0.49517277  0.50482723]\n",
      " [ 0.50760088  0.49239912]]\n",
      "[[ 0.49650465  0.50349535]\n",
      " [ 0.51669655  0.48330345]\n",
      " [ 0.50867714  0.49132286]\n",
      " ..., \n",
      " [ 0.49454345  0.50545655]\n",
      " [ 0.49511626  0.50488374]\n",
      " [ 0.50685402  0.49314598]]\n",
      "[[ 0.49596402  0.50403598]\n",
      " [ 0.51657614  0.48342386]\n",
      " [ 0.50749609  0.49250391]\n",
      " ..., \n",
      " [ 0.49410609  0.50589391]\n",
      " [ 0.49464873  0.50535127]\n",
      " [ 0.50725173  0.49274827]]\n",
      "[[ 0.49751826  0.50248174]\n",
      " [ 0.51516213  0.48483787]\n",
      " [ 0.50653512  0.49346488]\n",
      " ..., \n",
      " [ 0.49575313  0.50424687]\n",
      " [ 0.49626867  0.50373133]\n",
      " [ 0.50630296  0.49369704]]\n",
      "[[ 0.49791555  0.50208445]\n",
      " [ 0.51471941  0.48528059]\n",
      " [ 0.50650303  0.49349697]\n",
      " ..., \n",
      " [ 0.49623445  0.50376555]\n",
      " [ 0.49503534  0.50496466]\n",
      " [ 0.50628192  0.49371808]]\n",
      "[[ 0.49798601  0.50201399]\n",
      " [ 0.51402644  0.48597356]\n",
      " [ 0.50618319  0.49381681]\n",
      " ..., \n",
      " [ 0.49638132  0.50361868]\n",
      " [ 0.49523671  0.50476329]\n",
      " [ 0.50597213  0.49402787]]\n",
      "[[ 0.49837712  0.50162288]\n",
      " [ 0.51372022  0.48627978]\n",
      " [ 0.50621788  0.49378212]\n",
      " ..., \n",
      " [ 0.49684219  0.50315781]\n",
      " [ 0.49574732  0.50425268]\n",
      " [ 0.50483655  0.49516345]]\n",
      "[[ 0.49812622  0.50187378]\n",
      " [ 0.5128305   0.4871695 ]\n",
      " [ 0.50564034  0.49435966]\n",
      " ..., \n",
      " [ 0.49785305  0.50214695]\n",
      " [ 0.49680378  0.50319622]\n",
      " [ 0.50431654  0.49568346]]\n",
      "[[ 0.49753754  0.50246246]\n",
      " [ 0.5127587   0.4872413 ]\n",
      " [ 0.50585617  0.49414383]\n",
      " ..., \n",
      " [ 0.49727531  0.50272469]\n",
      " [ 0.49626802  0.50373198]\n",
      " [ 0.50458533  0.49541467]]\n",
      "[[ 0.49813689  0.50186311]\n",
      " [ 0.51181742  0.48818258]\n",
      " [ 0.50517999  0.49482001]\n",
      " ..., \n",
      " [ 0.49788474  0.50211526]\n",
      " [ 0.49691617  0.50308383]\n",
      " [ 0.50395799  0.49604201]]\n",
      "[[ 0.49858441  0.50141559]\n",
      " [ 0.51175821  0.48824179]\n",
      " [ 0.50536663  0.49463337]\n",
      " ..., \n",
      " [ 0.49834159  0.50165841]\n",
      " [ 0.4964347   0.5035653 ]\n",
      " [ 0.50321573  0.49678427]]\n",
      "[[ 0.49857937  0.50142063]\n",
      " [ 0.51128286  0.48871714]\n",
      " [ 0.50511939  0.49488061]\n",
      " ..., \n",
      " [ 0.49834523  0.50165477]\n",
      " [ 0.49650644  0.50349356]\n",
      " [ 0.50712872  0.49287128]]\n",
      "[[ 0.49870686  0.50129314]\n",
      " [ 0.51097238  0.48902762]\n",
      " [ 0.50502136  0.49497864]\n",
      " ..., \n",
      " [ 0.49848079  0.50151921]\n",
      " [ 0.4967054   0.5032946 ]\n",
      " [ 0.50494495  0.49505505]]\n",
      "[[ 0.49852008  0.50147992]\n",
      " [ 0.51131691  0.48868309]\n",
      " [ 0.50462413  0.49537587]\n",
      " ..., \n",
      " [ 0.49830154  0.50169846]\n",
      " [ 0.49658534  0.50341466]\n",
      " [ 0.50549056  0.49450944]]\n",
      "[[ 0.49903552  0.50096448]\n",
      " [ 0.5106808   0.4893192 ]\n",
      " [ 0.50494264  0.49505736]\n",
      " ..., \n",
      " [ 0.49882404  0.50117596]\n",
      " [ 0.49716318  0.50283682]\n",
      " [ 0.50504219  0.49495781]]\n",
      "[[ 0.49898508  0.50101492]\n",
      " [ 0.51026657  0.48973343]\n",
      " [ 0.50470762  0.49529238]\n",
      " ..., \n",
      " [ 0.49878021  0.50121979]\n",
      " [ 0.49717125  0.50282875]\n",
      " [ 0.50657642  0.49342358]]\n",
      "[[ 0.49903486  0.50096514]\n",
      " [ 0.50997456  0.49002544]\n",
      " [ 0.50458399  0.49541601]\n",
      " ..., \n",
      " [ 0.49883619  0.50116381]\n",
      " [ 0.49727599  0.50272401]\n",
      " [ 0.50639617  0.49360383]]\n",
      "[[ 0.49922934  0.50077066]\n",
      " [ 0.50904132  0.49095868]\n",
      " [ 0.50461525  0.49538475]\n",
      " ..., \n",
      " [ 0.49903651  0.50096349]\n",
      " [ 0.49752219  0.50247781]\n",
      " [ 0.50556799  0.49443201]]\n",
      "[[ 0.49864512  0.50135488]\n",
      " [ 0.50896005  0.49103995]\n",
      " [ 0.5038772   0.4961228 ]\n",
      " ..., \n",
      " [ 0.4992411   0.5007589 ]\n",
      " [ 0.49777004  0.50222996]\n",
      " [ 0.50558595  0.49441405]]\n",
      "[[ 0.49863262  0.50136738]\n",
      " [ 0.50866109  0.49133891]\n",
      " [ 0.50371937  0.49628063]\n",
      " ..., \n",
      " [ 0.49921204  0.50078796]\n",
      " [ 0.49778185  0.50221815]\n",
      " [ 0.50538067  0.49461933]]\n",
      "[[ 0.49874201  0.50125799]\n",
      " [ 0.50849946  0.49150054]\n",
      " [ 0.50369128  0.49630872]\n",
      " ..., \n",
      " [ 0.49930576  0.50069424]\n",
      " [ 0.49791422  0.50208578]\n",
      " [ 0.50405977  0.49594023]]\n",
      "[[ 0.49856834  0.50143166]\n",
      " [ 0.50856282  0.49143718]\n",
      " [ 0.50338738  0.49661262]\n",
      " ..., \n",
      " [ 0.49911726  0.50088274]\n",
      " [ 0.49776234  0.50223766]\n",
      " [ 0.50423999  0.49576001]]\n",
      "[[ 0.49898737  0.50101263]\n",
      " [ 0.50817815  0.49182185]\n",
      " [ 0.50313534  0.49686466]\n",
      " ..., \n",
      " [ 0.49952221  0.50047779]\n",
      " [ 0.49820203  0.50179797]\n",
      " [ 0.5039661   0.4960339 ]]\n",
      "[[ 0.49907229  0.50092771]\n",
      " [ 0.50803333  0.49196667]\n",
      " [ 0.50311656  0.49688344]\n",
      " ..., \n",
      " [ 0.49959377  0.50040623]\n",
      " [ 0.49830659  0.50169341]\n",
      " [ 0.50392655  0.49607345]]\n",
      "[[ 0.49900951  0.50099049]\n",
      " [ 0.50775204  0.49224796]\n",
      " [ 0.50295515  0.49704485]\n",
      " ..., \n",
      " [ 0.49951827  0.50048173]\n",
      " [ 0.49826249  0.50173751]\n",
      " [ 0.50374539  0.49625461]]\n",
      "[[ 0.49879663  0.50120337]\n",
      " [ 0.5077616   0.4922384 ]\n",
      " [ 0.50264833  0.49735167]\n",
      " ..., \n",
      " [ 0.49929327  0.50070673]\n",
      " [ 0.49806739  0.50193261]\n",
      " [ 0.50385035  0.49614965]]\n",
      "[[ 0.49910321  0.50089679]\n",
      " [ 0.50785966  0.49214034]\n",
      " [ 0.50286533  0.49713467]\n",
      " ..., \n",
      " [ 0.49914444  0.50085556]\n",
      " [ 0.49794707  0.50205293]\n",
      " [ 0.50359556  0.49640444]]\n",
      "[[ 0.49899022  0.50100978]\n",
      " [ 0.50754772  0.49245228]\n",
      " [ 0.50266684  0.49733316]\n",
      " ..., \n",
      " [ 0.49903052  0.50096948]\n",
      " [ 0.49847557  0.50152443]\n",
      " [ 0.50338048  0.49661952]]\n",
      "[[ 0.49910984  0.50089016]\n",
      " [ 0.50747718  0.49252282]\n",
      " [ 0.50270476  0.49729524]\n",
      " ..., \n",
      " [ 0.49838821  0.50161179]\n",
      " [ 0.49784561  0.50215439]\n",
      " [ 0.50340254  0.49659746]]\n",
      "[[ 0.499287    0.500713  ]\n",
      " [ 0.50709457  0.49290543]\n",
      " [ 0.50242584  0.49757416]\n",
      " ..., \n",
      " [ 0.49858106  0.50141894]\n",
      " [ 0.49805025  0.50194975]\n",
      " [ 0.50310845  0.49689155]]\n",
      "[[ 0.49909967  0.50090033]\n",
      " [ 0.50717174  0.49282826]\n",
      " [ 0.50260236  0.49739764]\n",
      " ..., \n",
      " [ 0.49840875  0.50159125]\n",
      " [ 0.49788923  0.50211077]\n",
      " [ 0.50327045  0.49672955]]\n",
      "[[ 0.49927455  0.50072545]\n",
      " [ 0.50680805  0.49319195]\n",
      " [ 0.50270426  0.49729574]\n",
      " ..., \n",
      " [ 0.49859802  0.50140198]\n",
      " [ 0.49808932  0.50191068]\n",
      " [ 0.50298798  0.49701202]]\n",
      "[[ 0.49898454  0.50101546]\n",
      " [ 0.50681078  0.49318922]\n",
      " [ 0.50234427  0.49765573]\n",
      " ..., \n",
      " [ 0.49876831  0.50123169]\n",
      " [ 0.49827     0.50173   ]\n",
      " [ 0.50306868  0.49693132]]\n",
      "[[ 0.49894634  0.50105366]\n",
      " [ 0.50661609  0.49338391]\n",
      " [ 0.50223888  0.49776112]\n",
      " ..., \n",
      " [ 0.49873444  0.50126556]\n",
      " [ 0.49824609  0.50175391]\n",
      " [ 0.50294881  0.49705119]]\n",
      "[[ 0.49896443  0.50103557]\n",
      " [ 0.5064838   0.4935162 ]\n",
      " [ 0.50219241  0.49780759]\n",
      " ..., \n",
      " [ 0.49875668  0.50124332]\n",
      " [ 0.4982779   0.5017221 ]\n",
      " [ 0.50288841  0.49711159]]\n",
      "[[ 0.49902309  0.50097691]\n",
      " [ 0.50639787  0.49360213]\n",
      " [ 0.50218899  0.49781101]\n",
      " ..., \n",
      " [ 0.49881933  0.50118067]\n",
      " [ 0.49834977  0.50165023]\n",
      " [ 0.50287161  0.49712839]]\n",
      "[[ 0.49926034  0.50073966]\n",
      " [ 0.5061827   0.4938173 ]\n",
      " [ 0.50205321  0.49794679]\n",
      " ..., \n",
      " [ 0.49906043  0.50093957]\n",
      " [ 0.49859972  0.50140028]\n",
      " [ 0.50272296  0.49727704]]\n",
      "[[ 0.49922478  0.50077522]\n",
      " [ 0.50601897  0.49398103]\n",
      " [ 0.50196594  0.49803406]\n",
      " ..., \n",
      " [ 0.49902858  0.50097142]\n",
      " [ 0.4985764   0.5014236 ]\n",
      " [ 0.50262328  0.49737672]]\n",
      "[[ 0.49923094  0.50076906]\n",
      " [ 0.5059016   0.4940984 ]\n",
      " [ 0.50192225  0.49807775]\n",
      " ..., \n",
      " [ 0.49903829  0.50096171]\n",
      " [ 0.49859434  0.50140566]\n",
      " [ 0.50256764  0.49743236]]\n",
      "[[ 0.49926512  0.50073488]\n",
      " [ 0.50581667  0.49418333]\n",
      " [ 0.50190837  0.49809163]\n",
      " ..., \n",
      " [ 0.49907592  0.50092408]\n",
      " [ 0.49863989  0.50136011]\n",
      " [ 0.50254224  0.49745776]]\n",
      "[[ 0.4992004   0.5007996 ]\n",
      " [ 0.50563703  0.49436297]\n",
      " [ 0.50179728  0.49820272]\n",
      " ..., \n",
      " [ 0.49901452  0.50098548]\n",
      " [ 0.49858614  0.50141386]\n",
      " [ 0.50242003  0.49757997]]\n",
      "[[ 0.49911788  0.50088212]\n",
      " [ 0.50544355  0.49455645]\n",
      " [ 0.50166999  0.49833001]\n",
      " ..., \n",
      " [ 0.49919717  0.50080283]\n",
      " [ 0.49877618  0.50122382]\n",
      " [ 0.502282    0.497718  ]]\n",
      "[[ 0.49911734  0.50088266]\n",
      " [ 0.50533581  0.49466419]\n",
      " [ 0.50162619  0.49837381]\n",
      " ..., \n",
      " [ 0.49919529  0.50080471]\n",
      " [ 0.49878143  0.50121857]\n",
      " [ 0.50337794  0.49662206]]\n",
      "[[ 0.4991884   0.5008116 ]\n",
      " [ 0.50530323  0.49469677]\n",
      " [ 0.50165544  0.49834456]\n",
      " ..., \n",
      " [ 0.49926505  0.50073495]\n",
      " [ 0.49885809  0.50114191]\n",
      " [ 0.5029222   0.4970778 ]]\n",
      "[[ 0.49918505  0.50081495]\n",
      " [ 0.50519964  0.49480036]\n",
      " [ 0.50161165  0.49838835]\n",
      " ..., \n",
      " [ 0.49926044  0.50073956]\n",
      " [ 0.49886015  0.50113985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.50285764  0.49714236]]\n",
      "[[ 0.4991404   0.5008596 ]\n",
      " [ 0.50540281  0.49459719]\n",
      " [ 0.50152786  0.49847214]\n",
      " ..., \n",
      " [ 0.49921457  0.50078543]\n",
      " [ 0.49882074  0.50117926]\n",
      " [ 0.50309859  0.49690141]]\n",
      "[[ 0.49927243  0.50072757]\n",
      " [ 0.50543543  0.49456457]\n",
      " [ 0.50162199  0.49837801]\n",
      " ..., \n",
      " [ 0.49910997  0.50089003]\n",
      " [ 0.49872239  0.50127761]\n",
      " [ 0.50293234  0.49706766]]\n",
      "[[ 0.49923363  0.50076637]\n",
      " [ 0.50530035  0.49469965]\n",
      " [ 0.50154648  0.49845352]\n",
      " ..., \n",
      " [ 0.49907372  0.50092628]\n",
      " [ 0.49869219  0.50130781]\n",
      " [ 0.50283637  0.49716363]]\n",
      "[[ 0.49929815  0.50070185]\n",
      " [ 0.50527153  0.49472847]\n",
      " [ 0.50157542  0.49842458]\n",
      " ..., \n",
      " [ 0.49879184  0.50120816]\n",
      " [ 0.49841618  0.50158382]\n",
      " [ 0.50284546  0.49715454]]\n",
      "[[ 0.49941691  0.50058309]\n",
      " [ 0.50506453  0.49493547]\n",
      " [ 0.5014244   0.4985756 ]\n",
      " ..., \n",
      " [ 0.49891827  0.50108173]\n",
      " [ 0.49854831  0.50145169]\n",
      " [ 0.5026752   0.4973248 ]]\n",
      "[[ 0.49929781  0.50070219]\n",
      " [ 0.50508638  0.49491362]\n",
      " [ 0.50150058  0.49849942]\n",
      " ..., \n",
      " [ 0.49880661  0.50119339]\n",
      " [ 0.49844217  0.50155783]\n",
      " [ 0.50273271  0.49726729]]\n",
      "[[ 0.49928307  0.50071693]\n",
      " [ 0.50498652  0.49501348]\n",
      " [ 0.50145344  0.49854656]\n",
      " ..., \n",
      " [ 0.49879909  0.50120091]\n",
      " [ 0.49844001  0.50155999]\n",
      " [ 0.50266745  0.49733255]]\n",
      "[[ 0.499305    0.500695  ]\n",
      " [ 0.5049258   0.4950742 ]\n",
      " [ 0.50144393  0.49855607]\n",
      " ..., \n",
      " [ 0.49882804  0.50117196]\n",
      " [ 0.49847416  0.50152584]\n",
      " [ 0.50264034  0.49735966]]\n",
      "[[ 0.49924963  0.50075037]\n",
      " [ 0.50479013  0.49520987]\n",
      " [ 0.50135799  0.49864201]\n",
      " ..., \n",
      " [ 0.4989938   0.5010062 ]\n",
      " [ 0.49864498  0.50135502]\n",
      " [ 0.50253732  0.49746268]]\n",
      "[[ 0.4993371   0.5006629 ]\n",
      " [ 0.50479957  0.49520043]\n",
      " [ 0.50141577  0.49858423]\n",
      " ..., \n",
      " [ 0.49908488  0.50091512]\n",
      " [ 0.49874097  0.50125903]\n",
      " [ 0.50231482  0.49768518]]\n",
      "[[ 0.49922342  0.50077658]\n",
      " [ 0.50481777  0.49518223]\n",
      " [ 0.50127323  0.49872677]\n",
      " ..., \n",
      " [ 0.4989747   0.5010253 ]\n",
      " [ 0.49863557  0.50136443]\n",
      " [ 0.50236753  0.49763247]]\n",
      "[[ 0.49931055  0.50068945]\n",
      " [ 0.50463247  0.49536753]\n",
      " [ 0.50133227  0.49866773]\n",
      " ..., \n",
      " [ 0.49906524  0.50093476]\n",
      " [ 0.49873075  0.50126925]\n",
      " [ 0.50221578  0.49778422]]\n",
      "[[ 0.49914188  0.50085812]\n",
      " [ 0.50461806  0.49538194]\n",
      " [ 0.50136246  0.49863754]\n",
      " ..., \n",
      " [ 0.49912606  0.50087394]\n",
      " [ 0.49856992  0.50143008]\n",
      " [ 0.50223403  0.49776597]]\n",
      "[[ 0.49921783  0.50078217]\n",
      " [ 0.5044291   0.4955709 ]\n",
      " [ 0.5014088   0.4985912 ]\n",
      " ..., \n",
      " [ 0.49920222  0.50079778]\n",
      " [ 0.49865349  0.50134651]\n",
      " [ 0.50226875  0.49773125]]\n",
      "[[ 0.49919558  0.50080442]\n",
      " [ 0.50459144  0.49540856]\n",
      " [ 0.50135773  0.49864227]\n",
      " ..., \n",
      " [ 0.49918018  0.50081982]\n",
      " [ 0.49863867  0.50136133]\n",
      " [ 0.50220636  0.49779364]]\n",
      "[[ 0.49935794  0.50064206]\n",
      " [ 0.5044932   0.4955068 ]\n",
      " [ 0.501492    0.498508  ]\n",
      " ..., \n",
      " [ 0.49915221  0.50084779]\n",
      " [ 0.49861774  0.50138226]\n",
      " [ 0.50213909  0.49786091]]\n",
      "[[ 0.49939982  0.50060018]\n",
      " [ 0.50446924  0.49553076]\n",
      " [ 0.50127709  0.49872291]\n",
      " ..., \n",
      " [ 0.49919673  0.50080327]\n",
      " [ 0.4986691   0.5013309 ]\n",
      " [ 0.50214531  0.49785469]]\n",
      "[[ 0.49939566  0.50060434]\n",
      " [ 0.50440092  0.49559908]\n",
      " [ 0.50124917  0.49875083]\n",
      " ..., \n",
      " [ 0.49919514  0.50080486]\n",
      " [ 0.4986742   0.5013258 ]\n",
      " [ 0.50210641  0.49789359]]\n",
      "[[ 0.49940929  0.50059071]\n",
      " [ 0.50435198  0.49564802]\n",
      " [ 0.50123963  0.49876037]\n",
      " ..., \n",
      " [ 0.49921128  0.50078872]\n",
      " [ 0.49869685  0.50130315]\n",
      " [ 0.50208615  0.49791385]]\n",
      "[[ 0.49941207  0.50058793]\n",
      " [ 0.50429375  0.49570625]\n",
      " [ 0.50121981  0.49878019]\n",
      " ..., \n",
      " [ 0.4992165   0.5007835 ]\n",
      " [ 0.49870842  0.50129158]\n",
      " [ 0.50205588  0.49794412]]\n",
      "[[ 0.49943063  0.50056937]\n",
      " [ 0.50425277  0.49574723]\n",
      " [ 0.50121632  0.49878368]\n",
      " ..., \n",
      " [ 0.49923744  0.50076256]\n",
      " [ 0.49873556  0.50126444]\n",
      " [ 0.5020422   0.4979578 ]]\n",
      "[[ 0.49941642  0.50058358]\n",
      " [ 0.50418047  0.49581953]\n",
      " [ 0.5011806   0.4988194 ]\n",
      " ..., \n",
      " [ 0.49922557  0.50077443]\n",
      " [ 0.49872973  0.50127027]\n",
      " [ 0.50199653  0.49800347]]\n",
      "[[ 0.49938596  0.50061404]\n",
      " [ 0.5040933   0.4959067 ]\n",
      " [ 0.50112914  0.49887086]\n",
      " ..., \n",
      " [ 0.49935253  0.50064747]\n",
      " [ 0.49870744  0.50129256]\n",
      " [ 0.5020905   0.4979095 ]]\n",
      "[[ 0.49939223  0.50060777]\n",
      " [ 0.50404419  0.49595581]\n",
      " [ 0.5011149   0.4988851 ]\n",
      " ..., \n",
      " [ 0.4993592   0.5006408 ]\n",
      " [ 0.49872169  0.50127831]\n",
      " [ 0.50206496  0.49793504]]\n",
      "[[ 0.49940743  0.50059257]\n",
      " [ 0.5040053   0.4959947 ]\n",
      " [ 0.50111007  0.49888993]\n",
      " ..., \n",
      " [ 0.49937478  0.50062522]\n",
      " [ 0.49874469  0.50125531]\n",
      " [ 0.50204908  0.49795092]]\n",
      "[[ 0.49938897  0.50061103]\n",
      " [ 0.503934    0.496066  ]\n",
      " [ 0.50107204  0.49892796]\n",
      " ..., \n",
      " [ 0.4993567   0.5006433 ]\n",
      " [ 0.49890724  0.50109276]\n",
      " [ 0.50200026  0.49799974]]\n",
      "[[ 0.49937294  0.50062706]\n",
      " [ 0.50386632  0.49613368]\n",
      " [ 0.50103689  0.49896311]\n",
      " ..., \n",
      " [ 0.49934104  0.50065896]\n",
      " [ 0.49889668  0.50110332]\n",
      " [ 0.50214527  0.49785473]]\n",
      "[[ 0.4994173   0.5005827 ]\n",
      " [ 0.50386019  0.49613981]\n",
      " [ 0.50106255  0.49893745]\n",
      " ..., \n",
      " [ 0.49938576  0.50061424]\n",
      " [ 0.49894639  0.50105361]\n",
      " [ 0.50195822  0.49804178]]\n",
      "[[ 0.49936755  0.50063245]\n",
      " [ 0.50389772  0.49610228]\n",
      " [ 0.50099452  0.49900548]\n",
      " ..., \n",
      " [ 0.49933636  0.50066364]\n",
      " [ 0.49890187  0.50109813]\n",
      " [ 0.50201689  0.49798311]]\n",
      "[[ 0.49943151  0.50056849]\n",
      " [ 0.50374423  0.49625577]\n",
      " [ 0.5010406   0.4989594 ]\n",
      " ..., \n",
      " [ 0.49940066  0.50059934]\n",
      " [ 0.49897095  0.50102905]\n",
      " [ 0.50188405  0.49811595]]\n",
      "[[ 0.49935629  0.50064371]\n",
      " [ 0.50375274  0.49624726]\n",
      " [ 0.50094789  0.49905211]\n",
      " ..., \n",
      " [ 0.49932577  0.50067423]\n",
      " [ 0.49890073  0.50109927]\n",
      " [ 0.50191279  0.49808721]]\n",
      "[[ 0.49945538  0.50054462]\n",
      " [ 0.50367279  0.49632721]\n",
      " [ 0.5008981   0.4991019 ]\n",
      " ..., \n",
      " [ 0.49942519  0.50057481]\n",
      " [ 0.49900472  0.50099528]\n",
      " [ 0.50185262  0.49814738]]\n",
      "[[ 0.49949132  0.50050868]\n",
      " [ 0.50366388  0.49633612]\n",
      " [ 0.5009187   0.4990813 ]\n",
      " ..., \n",
      " [ 0.49946145  0.50053855]\n",
      " [ 0.4988848   0.5011152 ]\n",
      " [ 0.50186306  0.49813694]]\n",
      "[[ 0.49951226  0.50048774]\n",
      " [ 0.50364089  0.49635911]\n",
      " [ 0.50092461  0.49907539]\n",
      " ..., \n",
      " [ 0.49948271  0.50051729]\n",
      " [ 0.49891212  0.50108788]\n",
      " [ 0.50165862  0.49834138]]\n",
      "[[ 0.49950576  0.50049424]\n",
      " [ 0.50359139  0.49640861]\n",
      " [ 0.5009034   0.4990966 ]\n",
      " ..., \n",
      " [ 0.49947651  0.50052349]\n",
      " [ 0.49891187  0.50108813]\n",
      " [ 0.50191029  0.49808971]]\n",
      "[[ 0.4995296   0.5004704 ]\n",
      " [ 0.5035731   0.4964269 ]\n",
      " [ 0.50091283  0.49908717]\n",
      " ..., \n",
      " [ 0.49950065  0.50049935]\n",
      " [ 0.49894183  0.50105817]\n",
      " [ 0.50170959  0.49829041]]\n",
      "[[ 0.49951343  0.50048657]\n",
      " [ 0.50351568  0.49648432]\n",
      " [ 0.50088255  0.49911745]\n",
      " ..., \n",
      " [ 0.49948478  0.50051522]\n",
      " [ 0.49893166  0.50106834]\n",
      " [ 0.50184523  0.49815477]]\n",
      "[[ 0.49953678  0.50046322]\n",
      " [ 0.5034986   0.4965014 ]\n",
      " [ 0.50089206  0.49910794]\n",
      " ..., \n",
      " [ 0.49950842  0.50049158]\n",
      " [ 0.49896089  0.50103911]\n",
      " [ 0.50160884  0.49839116]]\n",
      "[[ 0.49951589  0.50048411]\n",
      " [ 0.5035661   0.4964339 ]\n",
      " [ 0.50085762  0.49914238]\n",
      " ..., \n",
      " [ 0.49948781  0.50051219]\n",
      " [ 0.49894576  0.50105424]\n",
      " [ 0.50169524  0.49830476]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = clf.staged_predict_proba(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Train AUC: 0.6664\n",
      " Validation AUC: 0.6617\n"
     ]
    }
   ],
   "source": [
    "probs = clf.predict_proba(Xte)\n",
    "\n",
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC', metrics.roc_auc_score(ada_x_train, Ytr)))\n",
    "print(\"{0:>15}: {1:.4f}\".format('Validation AUC', metrics.roc_auc_score(ada_x_val, Yva)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ensemble(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self,X):\n",
    "        BTprobs = self.learners[0].predictSoft(Xte)\n",
    "        LCprobs = self.learners[1].predictSoft(XteP) \n",
    "        ADprobs = self.learners[2].predict_proba(Xte) \n",
    "        BTprobs = BTprobs * 0.4\n",
    "        LCprobs = LCprobs * 0.3\n",
    "        ADprobs = ADprobs * 0.3\n",
    "        return BTprobs + LCprobs + ADprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 161349 is out of bounds for axis 1 with size 160000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0536492c18ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0:>15}: {1:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train AUC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\College crap\\CS 178\\Final-project\\mltools\\base.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoft\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# sort data by score value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[0msorted_soft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 161349 is out of bounds for axis 1 with size 160000"
     ]
    }
   ],
   "source": [
    "ensemble = Ensemble([bt, linear, clf])\n",
    "ensemble.classes = np.unique(Y)\n",
    "\n",
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC', ensemble.auc(Xtr, Ytr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yte = np.vstack((np.arange(Xte.shape[0]), ensemble.predictSoft(Xte)[:,1])).T\n",
    "np.savetxt('Y_submit.txt', Yte, '%d, %.2f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier Y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yte = np.vstack((np.arange(XteP.shape[0]), linear.predictSoft(XteP)[:,1])).T\n",
    "np.savetxt('Y_submit.txt', Yte, '%d, %.2f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboosted Decision Stump Y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.72193886,  0.27806114],\n",
       "        [ 0.72193886,  0.27806114],\n",
       "        [ 0.72193886,  0.27806114],\n",
       "        ..., \n",
       "        [ 0.72193886,  0.27806114],\n",
       "        [ 0.72193886,  0.27806114],\n",
       "        [ 0.72193886,  0.27806114]]), array([[ 0.60557248,  0.39442752],\n",
       "        [ 0.60557248,  0.39442752],\n",
       "        [ 0.63932589,  0.36067411],\n",
       "        ..., \n",
       "        [ 0.63932589,  0.36067411],\n",
       "        [ 0.63932589,  0.36067411],\n",
       "        [ 0.63932589,  0.36067411]]), array([[ 0.56780193,  0.43219807],\n",
       "        [ 0.56780193,  0.43219807],\n",
       "        [ 0.59114219,  0.40885781],\n",
       "        ..., \n",
       "        [ 0.59114219,  0.40885781],\n",
       "        [ 0.59114219,  0.40885781],\n",
       "        [ 0.59114219,  0.40885781]]), array([[ 0.55780235,  0.44219765],\n",
       "        [ 0.55780235,  0.44219765],\n",
       "        [ 0.57544402,  0.42455598],\n",
       "        ..., \n",
       "        [ 0.57544402,  0.42455598],\n",
       "        [ 0.57544402,  0.42455598],\n",
       "        [ 0.57544402,  0.42455598]]), array([[ 0.52782732,  0.47217268],\n",
       "        [ 0.54878427,  0.45121573],\n",
       "        [ 0.56297384,  0.43702616],\n",
       "        ..., \n",
       "        [ 0.56297384,  0.43702616],\n",
       "        [ 0.56297384,  0.43702616],\n",
       "        [ 0.56297384,  0.43702616]]), array([[ 0.52668124,  0.47331876],\n",
       "        [ 0.54416113,  0.45583887],\n",
       "        [ 0.55601543,  0.44398457],\n",
       "        ..., \n",
       "        [ 0.55601543,  0.44398457],\n",
       "        [ 0.55601543,  0.44398457],\n",
       "        [ 0.55601543,  0.44398457]]), array([[ 0.52130056,  0.47869944],\n",
       "        [ 0.53630933,  0.46369067],\n",
       "        [ 0.54650291,  0.45349709],\n",
       "        ..., \n",
       "        [ 0.54650291,  0.45349709],\n",
       "        [ 0.54650291,  0.45349709],\n",
       "        [ 0.54650291,  0.45349709]]), array([[ 0.52001824,  0.47998176],\n",
       "        [ 0.53315762,  0.46684238],\n",
       "        [ 0.54208782,  0.45791218],\n",
       "        ..., \n",
       "        [ 0.54208782,  0.45791218],\n",
       "        [ 0.54208782,  0.45791218],\n",
       "        [ 0.54208782,  0.45791218]]), array([[ 0.51555769,  0.48444231],\n",
       "        [ 0.52724895,  0.47275105],\n",
       "        [ 0.53520101,  0.46479899],\n",
       "        ..., \n",
       "        [ 0.53520101,  0.46479899],\n",
       "        [ 0.53520101,  0.46479899],\n",
       "        [ 0.53520101,  0.46479899]]), array([[ 0.51494739,  0.48505261],\n",
       "        [ 0.52547171,  0.47452829],\n",
       "        [ 0.53263236,  0.46736764],\n",
       "        ..., \n",
       "        [ 0.53263236,  0.46736764],\n",
       "        [ 0.53263236,  0.46736764],\n",
       "        [ 0.53263236,  0.46736764]]), array([[ 0.51342642,  0.48657358],\n",
       "        [ 0.52299699,  0.47700301],\n",
       "        [ 0.52951073,  0.47048927],\n",
       "        ..., \n",
       "        [ 0.52951073,  0.47048927],\n",
       "        [ 0.52951073,  0.47048927],\n",
       "        [ 0.52951073,  0.47048927]]), array([[ 0.51139922,  0.48860078],\n",
       "        [ 0.52412662,  0.47587338],\n",
       "        [ 0.52614979,  0.47385021],\n",
       "        ..., \n",
       "        [ 0.52614979,  0.47385021],\n",
       "        [ 0.53009647,  0.46990353],\n",
       "        [ 0.53009647,  0.46990353]]), array([[ 0.51070184,  0.48929816],\n",
       "        [ 0.52245222,  0.47754778],\n",
       "        [ 0.5243204 ,  0.4756796 ],\n",
       "        ..., \n",
       "        [ 0.5243204 ,  0.4756796 ],\n",
       "        [ 0.52796506,  0.47203494],\n",
       "        [ 0.52796506,  0.47203494]]), array([[ 0.51008883,  0.48991117],\n",
       "        [ 0.52100141,  0.47899859],\n",
       "        [ 0.52273662,  0.47726338],\n",
       "        ..., \n",
       "        [ 0.52273662,  0.47726338],\n",
       "        [ 0.52612213,  0.47387787],\n",
       "        [ 0.52612213,  0.47387787]]), array([[ 0.50918126,  0.49081874],\n",
       "        [ 0.51936793,  0.48063207],\n",
       "        [ 0.52098793,  0.47901207],\n",
       "        ..., \n",
       "        [ 0.52098793,  0.47901207],\n",
       "        [ 0.52414885,  0.47585115],\n",
       "        [ 0.52414885,  0.47585115]]), array([[ 0.50907476,  0.49092524],\n",
       "        [ 0.51862526,  0.48137474],\n",
       "        [ 0.5201442 ,  0.4798558 ],\n",
       "        ..., \n",
       "        [ 0.5201442 ,  0.4798558 ],\n",
       "        [ 0.52310806,  0.47689194],\n",
       "        [ 0.52310806,  0.47689194]]), array([[ 0.50760088,  0.49239912],\n",
       "        [ 0.5189134 ,  0.4810866 ],\n",
       "        [ 0.52034293,  0.47965707],\n",
       "        ..., \n",
       "        [ 0.51802128,  0.48197872],\n",
       "        [ 0.52313239,  0.47686761],\n",
       "        [ 0.52081181,  0.47918819]]), array([[ 0.50685402,  0.49314598],\n",
       "        [ 0.51753927,  0.48246073],\n",
       "        [ 0.51888968,  0.48111032],\n",
       "        ..., \n",
       "        [ 0.51669655,  0.48330345],\n",
       "        [ 0.52152484,  0.47847516],\n",
       "        [ 0.51933261,  0.48066739]]), array([[ 0.50725173,  0.49274827],\n",
       "        [ 0.51589299,  0.48410701],\n",
       "        [ 0.51865389,  0.48134611],\n",
       "        ..., \n",
       "        [ 0.51657614,  0.48342386],\n",
       "        [ 0.52115049,  0.47884951],\n",
       "        [ 0.51907352,  0.48092648]]), array([[ 0.50630296,  0.49369704],\n",
       "        [ 0.51451303,  0.48548697],\n",
       "        [ 0.51713638,  0.48286362],\n",
       "        ..., \n",
       "        [ 0.51516213,  0.48483787],\n",
       "        [ 0.51950872,  0.48049128],\n",
       "        [ 0.51753512,  0.48246488]]), array([[ 0.50628192,  0.49371808],\n",
       "        [ 0.51410119,  0.48589881],\n",
       "        [ 0.51659977,  0.48340023],\n",
       "        ..., \n",
       "        [ 0.51471941,  0.48528059],\n",
       "        [ 0.51885934,  0.48114066],\n",
       "        [ 0.51697955,  0.48302045]]), array([[ 0.50597213,  0.49402787],\n",
       "        [ 0.51343628,  0.48656372],\n",
       "        [ 0.51582149,  0.48417851],\n",
       "        ..., \n",
       "        [ 0.51402644,  0.48597356],\n",
       "        [ 0.5179786 ,  0.4820214 ],\n",
       "        [ 0.51618405,  0.48381595]]), array([[ 0.506016  ,  0.493984  ],\n",
       "        [ 0.5131557 ,  0.4868443 ],\n",
       "        [ 0.51425875,  0.48574125],\n",
       "        ..., \n",
       "        [ 0.51372022,  0.48627978],\n",
       "        [ 0.5163225 ,  0.4836775 ],\n",
       "        [ 0.51578411,  0.48421589]]), array([[ 0.50544687,  0.49455313],\n",
       "        [ 0.51228945,  0.48771055],\n",
       "        [ 0.51454356,  0.48545644],\n",
       "        ..., \n",
       "        [ 0.5128305 ,  0.4871695 ],\n",
       "        [ 0.51652126,  0.48347874],\n",
       "        [ 0.5148086 ,  0.4851914 ]]), array([[ 0.50567044,  0.49432956],\n",
       "        [ 0.51113477,  0.48886523],\n",
       "        [ 0.51440325,  0.48559675],\n",
       "        ..., \n",
       "        [ 0.5127587 ,  0.4872413 ],\n",
       "        [ 0.51630188,  0.48369812],\n",
       "        [ 0.5146577 ,  0.4853423 ]]), array([[ 0.50500139,  0.49499861],\n",
       "        [ 0.51121105,  0.48878895],\n",
       "        [ 0.51435381,  0.48564619],\n",
       "        ..., \n",
       "        [ 0.51181742,  0.48818258],\n",
       "        [ 0.51617944,  0.48382056],\n",
       "        [ 0.51364357,  0.48635643]]), array([[ 0.50519465,  0.49480535],\n",
       "        [ 0.51117429,  0.48882571],\n",
       "        [ 0.51322719,  0.48677281],\n",
       "        ..., \n",
       "        [ 0.51175821,  0.48824179],\n",
       "        [ 0.51498544,  0.48501456],\n",
       "        [ 0.51351674,  0.48648326]]), array([[ 0.50495355,  0.49504645],\n",
       "        [ 0.51071977,  0.48928023],\n",
       "        [ 0.51269945,  0.48730055],\n",
       "        ..., \n",
       "        [ 0.51128286,  0.48871714],\n",
       "        [ 0.51439501,  0.48560499],\n",
       "        [ 0.51297867,  0.48702133]]), array([[ 0.50486124,  0.49513876],\n",
       "        [ 0.5104287 ,  0.4895713 ],\n",
       "        [ 0.51234016,  0.48765984],\n",
       "        ..., \n",
       "        [ 0.51097238,  0.48902762],\n",
       "        [ 0.51397733,  0.48602267],\n",
       "        [ 0.51260977,  0.48739023]]), array([[ 0.50446934,  0.49553066],\n",
       "        [ 0.50985137,  0.49014863],\n",
       "        [ 0.51263906,  0.48736094],\n",
       "        ..., \n",
       "        [ 0.51131691,  0.48868309],\n",
       "        [ 0.51422161,  0.48577839],\n",
       "        [ 0.51289967,  0.48710033]]), array([[ 0.5040539 ,  0.4959461 ],\n",
       "        [ 0.50926246,  0.49073754],\n",
       "        [ 0.51196038,  0.48803962],\n",
       "        ..., \n",
       "        [ 0.5106808 ,  0.4893192 ],\n",
       "        [ 0.51349199,  0.48650801],\n",
       "        [ 0.5122126 ,  0.4877874 ]]), array([[ 0.50384665,  0.49615335],\n",
       "        [ 0.50889252,  0.49110748],\n",
       "        [ 0.51150621,  0.48849379],\n",
       "        ..., \n",
       "        [ 0.51026657,  0.48973343],\n",
       "        [ 0.51299003,  0.48700997],\n",
       "        [ 0.51175056,  0.48824944]]), array([[ 0.5037491 ,  0.4962509 ],\n",
       "        [ 0.50864212,  0.49135788],\n",
       "        [ 0.51117667,  0.48882333],\n",
       "        ..., \n",
       "        [ 0.50997456,  0.49002544],\n",
       "        [ 0.51261557,  0.48738443],\n",
       "        [ 0.51141362,  0.48858638]]), array([[ 0.5029987 ,  0.4970013 ],\n",
       "        [ 0.50855403,  0.49144597],\n",
       "        [ 0.51101406,  0.48898594],\n",
       "        ..., \n",
       "        [ 0.50984729,  0.49015271],\n",
       "        [ 0.51241067,  0.48758933],\n",
       "        [ 0.51043816,  0.48956184]]), array([[ 0.50309007,  0.49690993],\n",
       "        [ 0.50848668,  0.49151332],\n",
       "        [ 0.51087644,  0.48912356],\n",
       "        ..., \n",
       "        [ 0.509743  ,  0.490257  ],\n",
       "        [ 0.51223317,  0.48776683],\n",
       "        [ 0.51031699,  0.48968301]]), array([[ 0.5029541 ,  0.4970459 ],\n",
       "        [ 0.50820086,  0.49179914],\n",
       "        [ 0.5105243 ,  0.4894757 ],\n",
       "        ..., \n",
       "        [ 0.50942231,  0.49057769],\n",
       "        [ 0.51184338,  0.48815662],\n",
       "        [ 0.50998037,  0.49001963]]), array([[ 0.50294669,  0.49705331],\n",
       "        [ 0.50805166,  0.49194834],\n",
       "        [ 0.51031233,  0.48968767],\n",
       "        ..., \n",
       "        [ 0.50924012,  0.49075988],\n",
       "        [ 0.51159579,  0.48840421],\n",
       "        [ 0.5097831 ,  0.4902169 ]]), array([[ 0.50266238,  0.49733762],\n",
       "        [ 0.50763309,  0.49236691],\n",
       "        [ 0.51032798,  0.48967202],\n",
       "        ..., \n",
       "        [ 0.50928398,  0.49071602],\n",
       "        [ 0.51157767,  0.48842233],\n",
       "        [ 0.50981268,  0.49018732]]), array([[ 0.50242893,  0.49757107],\n",
       "        [ 0.50727224,  0.49272776],\n",
       "        [ 0.50989811,  0.49010189],\n",
       "        ..., \n",
       "        [ 0.50888084,  0.49111916],\n",
       "        [ 0.51111579,  0.48888421],\n",
       "        [ 0.509396  ,  0.490604  ]]), array([[ 0.50242781,  0.49757219],\n",
       "        [ 0.50715006,  0.49284994],\n",
       "        [ 0.5097103 ,  0.4902897 ],\n",
       "        ..., \n",
       "        [ 0.50871846,  0.49128154],\n",
       "        [ 0.51089757,  0.48910243],\n",
       "        [ 0.50922074,  0.49077926]]), array([[ 0.5022832 ,  0.4977168 ],\n",
       "        [ 0.5068903 ,  0.4931097 ],\n",
       "        [ 0.50938815,  0.49061185],\n",
       "        ..., \n",
       "        [ 0.50842048,  0.49157952],\n",
       "        [ 0.51054649,  0.48945351],\n",
       "        [ 0.50891052,  0.49108948]]), array([[ 0.50242298,  0.49757702],\n",
       "        [ 0.50648984,  0.49351016],\n",
       "        [ 0.50935876,  0.49064124],\n",
       "        ..., \n",
       "        [ 0.50841412,  0.49158588],\n",
       "        [ 0.51048952,  0.48951048],\n",
       "        [ 0.5088925 ,  0.4911075 ]]), array([[ 0.50264522,  0.49735478],\n",
       "        [ 0.50617368,  0.49382632],\n",
       "        [ 0.50897595,  0.49102405],\n",
       "        ..., \n",
       "        [ 0.508497  ,  0.491503  ],\n",
       "        [ 0.51008045,  0.48991955],\n",
       "        [ 0.50896425,  0.49103575]]), array([[ 0.50245174,  0.49754826],\n",
       "        [ 0.50590004,  0.49409996],\n",
       "        [ 0.50925369,  0.49074631],\n",
       "        ..., \n",
       "        [ 0.50817059,  0.49182941],\n",
       "        [ 0.50971809,  0.49028191],\n",
       "        [ 0.50862723,  0.49137277]]), array([[ 0.50249444,  0.49750556],\n",
       "        [ 0.50586611,  0.49413389],\n",
       "        [ 0.50914525,  0.49085475],\n",
       "        ..., \n",
       "        [ 0.50808621,  0.49191379],\n",
       "        [ 0.50959933,  0.49040067],\n",
       "        [ 0.50853271,  0.49146729]]), array([[ 0.50222009,  0.49777991],\n",
       "        [ 0.50589638,  0.49410362],\n",
       "        [ 0.50910424,  0.49089576],\n",
       "        ..., \n",
       "        [ 0.50769038,  0.49230962],\n",
       "        [ 0.50954845,  0.49045155],\n",
       "        [ 0.50812718,  0.49187282]]), array([[ 0.50240099,  0.49759901],\n",
       "        [ 0.50556846,  0.49443154],\n",
       "        [ 0.50913864,  0.49086136],\n",
       "        ..., \n",
       "        [ 0.50775486,  0.49224514],\n",
       "        [ 0.5095734 ,  0.4904266 ],\n",
       "        [ 0.50818237,  0.49181763]]), array([[ 0.50250708,  0.49749292],\n",
       "        [ 0.50560856,  0.49439144],\n",
       "        [ 0.50873402,  0.49126598],\n",
       "        ..., \n",
       "        [ 0.50737904,  0.49262096],\n",
       "        [ 0.50915973,  0.49084027],\n",
       "        [ 0.50779764,  0.49220236]]), array([[ 0.5025976 ,  0.4974024 ],\n",
       "        [ 0.50563578,  0.49436422],\n",
       "        [ 0.50869745,  0.49130255],\n",
       "        ..., \n",
       "        [ 0.50737012,  0.49262988],\n",
       "        [ 0.50911448,  0.49088552],\n",
       "        [ 0.50778018,  0.49221982]]), array([[ 0.50248714,  0.49751286],\n",
       "        [ 0.50546457,  0.49453543],\n",
       "        [ 0.50846504,  0.49153496],\n",
       "        ..., \n",
       "        [ 0.50716424,  0.49283576],\n",
       "        [ 0.50887374,  0.49112626],\n",
       "        [ 0.50756611,  0.49243389]]), array([[ 0.5024358 ,  0.4975642 ],\n",
       "        [ 0.50535485,  0.49464515],\n",
       "        [ 0.50829652,  0.49170348],\n",
       "        ..., \n",
       "        [ 0.50702121,  0.49297879],\n",
       "        [ 0.50869721,  0.49130279],\n",
       "        [ 0.5074152 ,  0.4925848 ]]), array([[ 0.50242771,  0.49757229],\n",
       "        [ 0.50529063,  0.49470937],\n",
       "        [ 0.50817574,  0.49182426],\n",
       "        ..., \n",
       "        [ 0.50692494,  0.49307506],\n",
       "        [ 0.50856872,  0.49143128],\n",
       "        [ 0.50731136,  0.49268864]]), array([[ 0.50228742,  0.49771258],\n",
       "        [ 0.50509634,  0.49490366],\n",
       "        [ 0.50792705,  0.49207295],\n",
       "        ..., \n",
       "        [ 0.50669984,  0.49330016],\n",
       "        [ 0.50831262,  0.49168738],\n",
       "        [ 0.50707897,  0.49292103]]), array([[ 0.50219581,  0.49780419],\n",
       "        [ 0.50495272,  0.49504728],\n",
       "        [ 0.50773103,  0.49226897],\n",
       "        ..., \n",
       "        [ 0.50698336,  0.49301664],\n",
       "        [ 0.50810947,  0.49189053],\n",
       "        [ 0.50689865,  0.49310135]]), array([[ 0.50214794,  0.49785206],\n",
       "        [ 0.50485473,  0.49514527],\n",
       "        [ 0.50758255,  0.49241745],\n",
       "        ..., \n",
       "        [ 0.50684846,  0.49315154],\n",
       "        [ 0.50795411,  0.49204589],\n",
       "        [ 0.50676529,  0.49323471]]), array([[ 0.50213004,  0.49786996],\n",
       "        [ 0.5047885 ,  0.4952115 ],\n",
       "        [ 0.50746761,  0.49253239],\n",
       "        ..., \n",
       "        [ 0.50674663,  0.49325337],\n",
       "        [ 0.50783254,  0.49216746],\n",
       "        [ 0.50666495,  0.49333505]]), array([[ 0.502333  ,  0.497667  ],\n",
       "        [ 0.50462689,  0.49537311],\n",
       "        [ 0.50725903,  0.49274097],\n",
       "        ..., \n",
       "        [ 0.50686857,  0.49313143],\n",
       "        [ 0.50761756,  0.49238244],\n",
       "        [ 0.50647043,  0.49352957]]), array([[ 0.50219647,  0.49780353],\n",
       "        [ 0.50471277,  0.49528723],\n",
       "        [ 0.50729951,  0.49270049],\n",
       "        ..., \n",
       "        [ 0.50665387,  0.49334613],\n",
       "        [ 0.50765186,  0.49234814],\n",
       "        [ 0.50626259,  0.49373741]]), array([[ 0.50214375,  0.49785625],\n",
       "        [ 0.5046174 ,  0.4953826 ],\n",
       "        [ 0.50716032,  0.49283968],\n",
       "        ..., \n",
       "        [ 0.50652561,  0.49347439],\n",
       "        [ 0.5075067 ,  0.4924933 ],\n",
       "        [ 0.50614097,  0.49385903]]), array([[ 0.50216437,  0.49783563],\n",
       "        [ 0.5045968 ,  0.4954032 ],\n",
       "        [ 0.50664161,  0.49335839],\n",
       "        ..., \n",
       "        [ 0.50647321,  0.49352679],\n",
       "        [ 0.50743795,  0.49256205],\n",
       "        [ 0.50609498,  0.49390502]]), array([[ 0.50211223,  0.49788777],\n",
       "        [ 0.50450479,  0.49549521],\n",
       "        [ 0.50651609,  0.49348391],\n",
       "        ..., \n",
       "        [ 0.50635045,  0.49364955],\n",
       "        [ 0.50729938,  0.49270062],\n",
       "        [ 0.50597841,  0.49402159]]), array([[ 0.50202037,  0.49797963],\n",
       "        [ 0.50437434,  0.49562566],\n",
       "        [ 0.50635322,  0.49364678],\n",
       "        ..., \n",
       "        [ 0.50653504,  0.49346496],\n",
       "        [ 0.50712388,  0.49287612],\n",
       "        [ 0.50616901,  0.49383099]]), array([[ 0.50210668,  0.49789332],\n",
       "        [ 0.50442329,  0.49557671],\n",
       "        [ 0.50613533,  0.49386467],\n",
       "        ..., \n",
       "        [ 0.50654969,  0.49345031],\n",
       "        [ 0.50689377,  0.49310623],\n",
       "        [ 0.50618947,  0.49381053]]), array([[ 0.5020236 ,  0.4979764 ],\n",
       "        [ 0.50430402,  0.49569598],\n",
       "        [ 0.50598932,  0.49401068],\n",
       "        ..., \n",
       "        [ 0.50639721,  0.49360279],\n",
       "        [ 0.50673592,  0.49326408],\n",
       "        [ 0.50604261,  0.49395739]]), array([[ 0.5020452 ,  0.4979548 ],\n",
       "        [ 0.50429053,  0.49570947],\n",
       "        [ 0.50594991,  0.49405009],\n",
       "        ..., \n",
       "        [ 0.50635151,  0.49364849],\n",
       "        [ 0.50668502,  0.49331498],\n",
       "        [ 0.50600237,  0.49399763]]), array([[ 0.50188706,  0.49811294],\n",
       "        [ 0.50433364,  0.49566636],\n",
       "        [ 0.50596788,  0.49403212],\n",
       "        ..., \n",
       "        [ 0.50612816,  0.49387184],\n",
       "        [ 0.50669185,  0.49330815],\n",
       "        [ 0.5057843 ,  0.4942157 ]]), array([[ 0.50195634,  0.49804366],\n",
       "        [ 0.50414117,  0.49585883],\n",
       "        [ 0.50597624,  0.49402376],\n",
       "        ..., \n",
       "        [ 0.50613413,  0.49386587],\n",
       "        [ 0.50668941,  0.49331059],\n",
       "        [ 0.50579541,  0.49420459]]), array([[ 0.5019025 ,  0.4980975 ],\n",
       "        [ 0.5040552 ,  0.4959448 ],\n",
       "        [ 0.5058633 ,  0.4941367 ],\n",
       "        ..., \n",
       "        [ 0.50601887,  0.49398113],\n",
       "        [ 0.50656598,  0.49343402],\n",
       "        [ 0.50568512,  0.49431488]]), array([[ 0.50188647,  0.49811353],\n",
       "        [ 0.50400798,  0.49599202],\n",
       "        [ 0.50578987,  0.49421013],\n",
       "        ..., \n",
       "        [ 0.50594319,  0.49405681],\n",
       "        [ 0.50648237,  0.49351763],\n",
       "        [ 0.50561428,  0.49438572]]), array([[ 0.50179422,  0.49820578],\n",
       "        [ 0.50388543,  0.49611457],\n",
       "        [ 0.50585617,  0.49414383],\n",
       "        ..., \n",
       "        [ 0.505793  ,  0.494207  ],\n",
       "        [ 0.50653877,  0.49346123],\n",
       "        [ 0.50546879,  0.49453121]]), array([[ 0.50184585,  0.49815415],\n",
       "        [ 0.5039076 ,  0.4960924 ],\n",
       "        [ 0.50558694,  0.49441306],\n",
       "        ..., \n",
       "        [ 0.50578831,  0.49421169],\n",
       "        [ 0.50625994,  0.49374006],\n",
       "        [ 0.50546866,  0.49453134]]), array([[ 0.50169734,  0.49830266],\n",
       "        [ 0.50373046,  0.49626954],\n",
       "        [ 0.50559421,  0.49440579],\n",
       "        ..., \n",
       "        [ 0.50579277,  0.49420723],\n",
       "        [ 0.50625786,  0.49374214],\n",
       "        [ 0.50547757,  0.49452243]]), array([[ 0.50155477,  0.49844523],\n",
       "        [ 0.50375584,  0.49624416],\n",
       "        [ 0.50559406,  0.49440594],\n",
       "        ..., \n",
       "        [ 0.50559412,  0.49440588],\n",
       "        [ 0.50605284,  0.49394716],\n",
       "        [ 0.50528323,  0.49471677]]), array([[ 0.50158195,  0.49841805],\n",
       "        [ 0.50375328,  0.49624672],\n",
       "        [ 0.50556666,  0.49443334],\n",
       "        ..., \n",
       "        [ 0.50556672,  0.49443328],\n",
       "        [ 0.50601924,  0.49398076],\n",
       "        [ 0.50526003,  0.49473997]]), array([[ 0.50162536,  0.49837464],\n",
       "        [ 0.50376774,  0.49623226],\n",
       "        [ 0.50536506,  0.49463494],\n",
       "        ..., \n",
       "        [ 0.50536512,  0.49463488],\n",
       "        [ 0.50581161,  0.49418839],\n",
       "        [ 0.50506252,  0.49493748]]), array([[ 0.50157144,  0.49842856],\n",
       "        [ 0.50368563,  0.49631437],\n",
       "        [ 0.50526194,  0.49473806],\n",
       "        ..., \n",
       "        [ 0.50551514,  0.49448486],\n",
       "        [ 0.50570262,  0.49429738],\n",
       "        [ 0.50521652,  0.49478348]]), array([[ 0.50151242,  0.49848758],\n",
       "        [ 0.50359915,  0.49640085],\n",
       "        [ 0.50515499,  0.49484501],\n",
       "        ..., \n",
       "        [ 0.5054049 ,  0.4945951 ],\n",
       "        [ 0.50558995,  0.49441005],\n",
       "        [ 0.50511016,  0.49488984]]), array([[ 0.50152667,  0.49847333],\n",
       "        [ 0.50358666,  0.49641334],\n",
       "        [ 0.50512255,  0.49487745],\n",
       "        ..., \n",
       "        [ 0.50536926,  0.49463074],\n",
       "        [ 0.50555194,  0.49444806],\n",
       "        [ 0.5050783 ,  0.4949217 ]]), array([[ 0.5014956 ,  0.4985044 ],\n",
       "        [ 0.50352951,  0.49647049],\n",
       "        [ 0.50504596,  0.49495404],\n",
       "        ..., \n",
       "        [ 0.50528955,  0.49471045],\n",
       "        [ 0.50546991,  0.49453009],\n",
       "        [ 0.50500227,  0.49499773]]), array([[ 0.50148298,  0.49851702],\n",
       "        [ 0.50349146,  0.49650854],\n",
       "        [ 0.50498897,  0.49501103],\n",
       "        ..., \n",
       "        [ 0.50522951,  0.49477049],\n",
       "        [ 0.50540762,  0.49459238],\n",
       "        [ 0.50494582,  0.49505418]]), array([[ 0.50146016,  0.49853984],\n",
       "        [ 0.50344385,  0.49655615],\n",
       "        [ 0.50492287,  0.49507713],\n",
       "        ..., \n",
       "        [ 0.50516044,  0.49483956],\n",
       "        [ 0.50533635,  0.49466365],\n",
       "        [ 0.50488025,  0.49511975]]), array([[ 0.50145373,  0.49854627],\n",
       "        [ 0.50341324,  0.49658676],\n",
       "        [ 0.50487422,  0.49512578],\n",
       "        ..., \n",
       "        [ 0.50510889,  0.49489111],\n",
       "        [ 0.50528266,  0.49471734],\n",
       "        [ 0.50483212,  0.49516788]]), array([[ 0.50141515,  0.49858485],\n",
       "        [ 0.50335105,  0.49664895],\n",
       "        [ 0.50479443,  0.49520557],\n",
       "        ..., \n",
       "        [ 0.50502628,  0.49497372],\n",
       "        [ 0.50519796,  0.49480204],\n",
       "        [ 0.50475284,  0.49524716]]), array([[ 0.50151605,  0.49848395],\n",
       "        [ 0.50327375,  0.49672625],\n",
       "        [ 0.50469995,  0.49530005],\n",
       "        ..., \n",
       "        [ 0.50492904,  0.49507096],\n",
       "        [ 0.50509867,  0.49490133],\n",
       "        [ 0.50465886,  0.49534114]]), array([[ 0.50149726,  0.49850274],\n",
       "        [ 0.50323428,  0.49676572],\n",
       "        [ 0.50464371,  0.49535629],\n",
       "        ..., \n",
       "        [ 0.5048701 ,  0.4951299 ],\n",
       "        [ 0.50503774,  0.49496226],\n",
       "        [ 0.5046031 ,  0.4953969 ]]), array([[ 0.50148799,  0.49851201],\n",
       "        [ 0.50320481,  0.49679519],\n",
       "        [ 0.50459785,  0.49540215],\n",
       "        ..., \n",
       "        [ 0.50482161,  0.49517839],\n",
       "        [ 0.5049873 ,  0.4950127 ],\n",
       "        [ 0.50455771,  0.49544229]]), array([[ 0.50144562,  0.49855438],\n",
       "        [ 0.50314271,  0.49685729],\n",
       "        [ 0.50451974,  0.49548026],\n",
       "        ..., \n",
       "        [ 0.50474093,  0.49525907],\n",
       "        [ 0.50490471,  0.49509529],\n",
       "        [ 0.50448006,  0.49551994]]), array([[ 0.50159693,  0.49840307],\n",
       "        [ 0.50308402,  0.49691598],\n",
       "        [ 0.50444541,  0.49555459],\n",
       "        ..., \n",
       "        [ 0.50466409,  0.49533591],\n",
       "        [ 0.50482601,  0.49517399],\n",
       "        [ 0.50440618,  0.49559382]]), array([[ 0.50141604,  0.49858396],\n",
       "        [ 0.50308668,  0.49691332],\n",
       "        [ 0.50443277,  0.49556723],\n",
       "        ..., \n",
       "        [ 0.50464899,  0.49535101],\n",
       "        [ 0.5048091 ,  0.4951909 ],\n",
       "        [ 0.50419374,  0.49580626]]), array([[ 0.50134408,  0.49865592],\n",
       "        [ 0.50299616,  0.49700384],\n",
       "        [ 0.50446394,  0.49553606],\n",
       "        ..., \n",
       "        [ 0.50467776,  0.49532224],\n",
       "        [ 0.50483608,  0.49516392],\n",
       "        [ 0.50422757,  0.49577243]]), array([[ 0.50138632,  0.49861368],\n",
       "        [ 0.50302025,  0.49697975],\n",
       "        [ 0.50447189,  0.49552811],\n",
       "        ..., \n",
       "        [ 0.5045157 ,  0.4954843 ],\n",
       "        [ 0.50467228,  0.49532772],\n",
       "        [ 0.50407045,  0.49592955]]), array([[ 0.50142046,  0.49857954],\n",
       "        [ 0.50290602,  0.49709398],\n",
       "        [ 0.5044725 ,  0.4955275 ],\n",
       "        ..., \n",
       "        [ 0.50451582,  0.49548418],\n",
       "        [ 0.50467071,  0.49532929],\n",
       "        [ 0.50407541,  0.49592459]]), array([[ 0.50136559,  0.49863441],\n",
       "        [ 0.50283518,  0.49716482],\n",
       "        [ 0.50438481,  0.49561519],\n",
       "        ..., \n",
       "        [ 0.50442767,  0.49557233],\n",
       "        [ 0.50458089,  0.49541911],\n",
       "        [ 0.503992  ,  0.496008  ]]), array([[ 0.50138122,  0.49861878],\n",
       "        [ 0.50283517,  0.49716483],\n",
       "        [ 0.50436832,  0.49563168],\n",
       "        ..., \n",
       "        [ 0.50441072,  0.49558928],\n",
       "        [ 0.50456231,  0.49543769],\n",
       "        [ 0.50397968,  0.49602032]]), array([[ 0.50138226,  0.49861774],\n",
       "        [ 0.50282091,  0.49717909],\n",
       "        [ 0.50433792,  0.49566208],\n",
       "        ..., \n",
       "        [ 0.50437988,  0.49562012],\n",
       "        [ 0.50452987,  0.49547013],\n",
       "        [ 0.50395338,  0.49604662]]), array([[ 0.50135628,  0.49864372],\n",
       "        [ 0.50277994,  0.49722006],\n",
       "        [ 0.50428115,  0.49571885],\n",
       "        ..., \n",
       "        [ 0.50432268,  0.49567732],\n",
       "        [ 0.50447111,  0.49552889],\n",
       "        [ 0.50390061,  0.49609939]]), array([[ 0.50116129,  0.49883871],\n",
       "        [ 0.50277003,  0.49722997],\n",
       "        [ 0.50425576,  0.49574424],\n",
       "        ..., \n",
       "        [ 0.50429686,  0.49570314],\n",
       "        [ 0.50444376,  0.49555624],\n",
       "        [ 0.50367941,  0.49632059]]), array([[ 0.50130253,  0.49869747],\n",
       "        [ 0.5027208 ,  0.4972792 ],\n",
       "        [ 0.50419137,  0.49580863],\n",
       "        ..., \n",
       "        [ 0.50423205,  0.49576795],\n",
       "        [ 0.50437745,  0.49562255],\n",
       "        [ 0.5036209 ,  0.4963791 ]]), array([[ 0.50107162,  0.49892838],\n",
       "        [ 0.50271175,  0.49728825],\n",
       "        [ 0.50416747,  0.49583253],\n",
       "        ..., \n",
       "        [ 0.50420774,  0.49579226],\n",
       "        [ 0.50435167,  0.49564833],\n",
       "        [ 0.50360276,  0.49639724]]), array([[ 0.50103538,  0.49896462],\n",
       "        [ 0.50265911,  0.49734089],\n",
       "        [ 0.50410028,  0.49589972],\n",
       "        ..., \n",
       "        [ 0.50426814,  0.49573186],\n",
       "        [ 0.50428264,  0.49571736],\n",
       "        [ 0.50366921,  0.49633079]])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clf.staged_predict_proba(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(clf.staged_predict_proba(Xte)):\n",
    "    Yhat = learner[i].predict(X)\n",
    "    e = wts.dot( Y != Yhat ) # compute weighted error rate\n",
    "    alpha[i] = 0.5 * np.log( (1-e)/e )\n",
    "    wts *= np.exp( -alpha[i] * Y * Yhat ) # update weights\n",
    "    wts /= wts.sum() # and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (160000,) (160000,2) (160000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-c33006ccab53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstaged_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredict\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mel\u001b[0m \u001b[1;31m# compute contribution of each\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (160000,) (160000,2) (160000,) "
     ]
    }
   ],
   "source": [
    "predict = np.zeros((Xtr.shape[0], ))\n",
    "\n",
    "#my_array = [[] for x in range(Xte.shape[0])]\n",
    "for i, el in enumerate(clf.staged_predict_proba(Xtr)):\n",
    "    print(el.shape)\n",
    "    predict += el # compute contribution of each\n",
    "predict = np.sign(predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.27806114,  0.27806114,  0.27806114, ...,  0.27806114,\n",
       "         0.27806114,  0.27806114]),\n",
       " array([ 0.39442752,  0.39442752,  0.36067411, ...,  0.36067411,\n",
       "         0.36067411,  0.36067411]),\n",
       " array([ 0.43219807,  0.43219807,  0.40885781, ...,  0.40885781,\n",
       "         0.40885781,  0.40885781]),\n",
       " array([ 0.44219765,  0.44219765,  0.42455598, ...,  0.42455598,\n",
       "         0.42455598,  0.42455598]),\n",
       " array([ 0.47217268,  0.45121573,  0.43702616, ...,  0.43702616,\n",
       "         0.43702616,  0.43702616]),\n",
       " array([ 0.47331876,  0.45583887,  0.44398457, ...,  0.44398457,\n",
       "         0.44398457,  0.44398457]),\n",
       " array([ 0.47869944,  0.46369067,  0.45349709, ...,  0.45349709,\n",
       "         0.45349709,  0.45349709]),\n",
       " array([ 0.47998176,  0.46684238,  0.45791218, ...,  0.45791218,\n",
       "         0.45791218,  0.45791218]),\n",
       " array([ 0.48444231,  0.47275105,  0.46479899, ...,  0.46479899,\n",
       "         0.46479899,  0.46479899]),\n",
       " array([ 0.48505261,  0.47452829,  0.46736764, ...,  0.46736764,\n",
       "         0.46736764,  0.46736764]),\n",
       " array([ 0.48657358,  0.47700301,  0.47048927, ...,  0.47048927,\n",
       "         0.47048927,  0.47048927]),\n",
       " array([ 0.48860078,  0.47587338,  0.47385021, ...,  0.47385021,\n",
       "         0.46990353,  0.46990353]),\n",
       " array([ 0.48929816,  0.47754778,  0.4756796 , ...,  0.4756796 ,\n",
       "         0.47203494,  0.47203494]),\n",
       " array([ 0.48991117,  0.47899859,  0.47726338, ...,  0.47726338,\n",
       "         0.47387787,  0.47387787]),\n",
       " array([ 0.49081874,  0.48063207,  0.47901207, ...,  0.47901207,\n",
       "         0.47585115,  0.47585115]),\n",
       " array([ 0.49092524,  0.48137474,  0.4798558 , ...,  0.4798558 ,\n",
       "         0.47689194,  0.47689194]),\n",
       " array([ 0.49239912,  0.4810866 ,  0.47965707, ...,  0.48197872,\n",
       "         0.47686761,  0.47918819]),\n",
       " array([ 0.49314598,  0.48246073,  0.48111032, ...,  0.48330345,\n",
       "         0.47847516,  0.48066739]),\n",
       " array([ 0.49274827,  0.48410701,  0.48134611, ...,  0.48342386,\n",
       "         0.47884951,  0.48092648]),\n",
       " array([ 0.49369704,  0.48548697,  0.48286362, ...,  0.48483787,\n",
       "         0.48049128,  0.48246488]),\n",
       " array([ 0.49371808,  0.48589881,  0.48340023, ...,  0.48528059,\n",
       "         0.48114066,  0.48302045]),\n",
       " array([ 0.49402787,  0.48656372,  0.48417851, ...,  0.48597356,\n",
       "         0.4820214 ,  0.48381595]),\n",
       " array([ 0.493984  ,  0.4868443 ,  0.48574125, ...,  0.48627978,\n",
       "         0.4836775 ,  0.48421589]),\n",
       " array([ 0.49455313,  0.48771055,  0.48545644, ...,  0.4871695 ,\n",
       "         0.48347874,  0.4851914 ]),\n",
       " array([ 0.49432956,  0.48886523,  0.48559675, ...,  0.4872413 ,\n",
       "         0.48369812,  0.4853423 ]),\n",
       " array([ 0.49499861,  0.48878895,  0.48564619, ...,  0.48818258,\n",
       "         0.48382056,  0.48635643]),\n",
       " array([ 0.49480535,  0.48882571,  0.48677281, ...,  0.48824179,\n",
       "         0.48501456,  0.48648326]),\n",
       " array([ 0.49504645,  0.48928023,  0.48730055, ...,  0.48871714,\n",
       "         0.48560499,  0.48702133]),\n",
       " array([ 0.49513876,  0.4895713 ,  0.48765984, ...,  0.48902762,\n",
       "         0.48602267,  0.48739023]),\n",
       " array([ 0.49553066,  0.49014863,  0.48736094, ...,  0.48868309,\n",
       "         0.48577839,  0.48710033]),\n",
       " array([ 0.4959461 ,  0.49073754,  0.48803962, ...,  0.4893192 ,\n",
       "         0.48650801,  0.4877874 ]),\n",
       " array([ 0.49615335,  0.49110748,  0.48849379, ...,  0.48973343,\n",
       "         0.48700997,  0.48824944]),\n",
       " array([ 0.4962509 ,  0.49135788,  0.48882333, ...,  0.49002544,\n",
       "         0.48738443,  0.48858638]),\n",
       " array([ 0.4970013 ,  0.49144597,  0.48898594, ...,  0.49015271,\n",
       "         0.48758933,  0.48956184]),\n",
       " array([ 0.49690993,  0.49151332,  0.48912356, ...,  0.490257  ,\n",
       "         0.48776683,  0.48968301]),\n",
       " array([ 0.4970459 ,  0.49179914,  0.4894757 , ...,  0.49057769,\n",
       "         0.48815662,  0.49001963]),\n",
       " array([ 0.49705331,  0.49194834,  0.48968767, ...,  0.49075988,\n",
       "         0.48840421,  0.4902169 ]),\n",
       " array([ 0.49733762,  0.49236691,  0.48967202, ...,  0.49071602,\n",
       "         0.48842233,  0.49018732]),\n",
       " array([ 0.49757107,  0.49272776,  0.49010189, ...,  0.49111916,\n",
       "         0.48888421,  0.490604  ]),\n",
       " array([ 0.49757219,  0.49284994,  0.4902897 , ...,  0.49128154,\n",
       "         0.48910243,  0.49077926]),\n",
       " array([ 0.4977168 ,  0.4931097 ,  0.49061185, ...,  0.49157952,\n",
       "         0.48945351,  0.49108948]),\n",
       " array([ 0.49757702,  0.49351016,  0.49064124, ...,  0.49158588,\n",
       "         0.48951048,  0.4911075 ]),\n",
       " array([ 0.49735478,  0.49382632,  0.49102405, ...,  0.491503  ,\n",
       "         0.48991955,  0.49103575]),\n",
       " array([ 0.49754826,  0.49409996,  0.49074631, ...,  0.49182941,\n",
       "         0.49028191,  0.49137277]),\n",
       " array([ 0.49750556,  0.49413389,  0.49085475, ...,  0.49191379,\n",
       "         0.49040067,  0.49146729]),\n",
       " array([ 0.49777991,  0.49410362,  0.49089576, ...,  0.49230962,\n",
       "         0.49045155,  0.49187282]),\n",
       " array([ 0.49759901,  0.49443154,  0.49086136, ...,  0.49224514,\n",
       "         0.4904266 ,  0.49181763]),\n",
       " array([ 0.49749292,  0.49439144,  0.49126598, ...,  0.49262096,\n",
       "         0.49084027,  0.49220236]),\n",
       " array([ 0.4974024 ,  0.49436422,  0.49130255, ...,  0.49262988,\n",
       "         0.49088552,  0.49221982]),\n",
       " array([ 0.49751286,  0.49453543,  0.49153496, ...,  0.49283576,\n",
       "         0.49112626,  0.49243389]),\n",
       " array([ 0.4975642 ,  0.49464515,  0.49170348, ...,  0.49297879,\n",
       "         0.49130279,  0.4925848 ]),\n",
       " array([ 0.49757229,  0.49470937,  0.49182426, ...,  0.49307506,\n",
       "         0.49143128,  0.49268864]),\n",
       " array([ 0.49771258,  0.49490366,  0.49207295, ...,  0.49330016,\n",
       "         0.49168738,  0.49292103]),\n",
       " array([ 0.49780419,  0.49504728,  0.49226897, ...,  0.49301664,\n",
       "         0.49189053,  0.49310135]),\n",
       " array([ 0.49785206,  0.49514527,  0.49241745, ...,  0.49315154,\n",
       "         0.49204589,  0.49323471]),\n",
       " array([ 0.49786996,  0.4952115 ,  0.49253239, ...,  0.49325337,\n",
       "         0.49216746,  0.49333505]),\n",
       " array([ 0.497667  ,  0.49537311,  0.49274097, ...,  0.49313143,\n",
       "         0.49238244,  0.49352957]),\n",
       " array([ 0.49780353,  0.49528723,  0.49270049, ...,  0.49334613,\n",
       "         0.49234814,  0.49373741]),\n",
       " array([ 0.49785625,  0.4953826 ,  0.49283968, ...,  0.49347439,\n",
       "         0.4924933 ,  0.49385903]),\n",
       " array([ 0.49783563,  0.4954032 ,  0.49335839, ...,  0.49352679,\n",
       "         0.49256205,  0.49390502]),\n",
       " array([ 0.49788777,  0.49549521,  0.49348391, ...,  0.49364955,\n",
       "         0.49270062,  0.49402159]),\n",
       " array([ 0.49797963,  0.49562566,  0.49364678, ...,  0.49346496,\n",
       "         0.49287612,  0.49383099]),\n",
       " array([ 0.49789332,  0.49557671,  0.49386467, ...,  0.49345031,\n",
       "         0.49310623,  0.49381053]),\n",
       " array([ 0.4979764 ,  0.49569598,  0.49401068, ...,  0.49360279,\n",
       "         0.49326408,  0.49395739]),\n",
       " array([ 0.4979548 ,  0.49570947,  0.49405009, ...,  0.49364849,\n",
       "         0.49331498,  0.49399763]),\n",
       " array([ 0.49811294,  0.49566636,  0.49403212, ...,  0.49387184,\n",
       "         0.49330815,  0.4942157 ]),\n",
       " array([ 0.49804366,  0.49585883,  0.49402376, ...,  0.49386587,\n",
       "         0.49331059,  0.49420459]),\n",
       " array([ 0.4980975 ,  0.4959448 ,  0.4941367 , ...,  0.49398113,\n",
       "         0.49343402,  0.49431488]),\n",
       " array([ 0.49811353,  0.49599202,  0.49421013, ...,  0.49405681,\n",
       "         0.49351763,  0.49438572]),\n",
       " array([ 0.49820578,  0.49611457,  0.49414383, ...,  0.494207  ,\n",
       "         0.49346123,  0.49453121]),\n",
       " array([ 0.49815415,  0.4960924 ,  0.49441306, ...,  0.49421169,\n",
       "         0.49374006,  0.49453134]),\n",
       " array([ 0.49830266,  0.49626954,  0.49440579, ...,  0.49420723,\n",
       "         0.49374214,  0.49452243]),\n",
       " array([ 0.49844523,  0.49624416,  0.49440594, ...,  0.49440588,\n",
       "         0.49394716,  0.49471677]),\n",
       " array([ 0.49841805,  0.49624672,  0.49443334, ...,  0.49443328,\n",
       "         0.49398076,  0.49473997]),\n",
       " array([ 0.49837464,  0.49623226,  0.49463494, ...,  0.49463488,\n",
       "         0.49418839,  0.49493748]),\n",
       " array([ 0.49842856,  0.49631437,  0.49473806, ...,  0.49448486,\n",
       "         0.49429738,  0.49478348]),\n",
       " array([ 0.49848758,  0.49640085,  0.49484501, ...,  0.4945951 ,\n",
       "         0.49441005,  0.49488984]),\n",
       " array([ 0.49847333,  0.49641334,  0.49487745, ...,  0.49463074,\n",
       "         0.49444806,  0.4949217 ]),\n",
       " array([ 0.4985044 ,  0.49647049,  0.49495404, ...,  0.49471045,\n",
       "         0.49453009,  0.49499773]),\n",
       " array([ 0.49851702,  0.49650854,  0.49501103, ...,  0.49477049,\n",
       "         0.49459238,  0.49505418]),\n",
       " array([ 0.49853984,  0.49655615,  0.49507713, ...,  0.49483956,\n",
       "         0.49466365,  0.49511975]),\n",
       " array([ 0.49854627,  0.49658676,  0.49512578, ...,  0.49489111,\n",
       "         0.49471734,  0.49516788]),\n",
       " array([ 0.49858485,  0.49664895,  0.49520557, ...,  0.49497372,\n",
       "         0.49480204,  0.49524716]),\n",
       " array([ 0.49848395,  0.49672625,  0.49530005, ...,  0.49507096,\n",
       "         0.49490133,  0.49534114]),\n",
       " array([ 0.49850274,  0.49676572,  0.49535629, ...,  0.4951299 ,\n",
       "         0.49496226,  0.4953969 ]),\n",
       " array([ 0.49851201,  0.49679519,  0.49540215, ...,  0.49517839,\n",
       "         0.4950127 ,  0.49544229]),\n",
       " array([ 0.49855438,  0.49685729,  0.49548026, ...,  0.49525907,\n",
       "         0.49509529,  0.49551994]),\n",
       " array([ 0.49840307,  0.49691598,  0.49555459, ...,  0.49533591,\n",
       "         0.49517399,  0.49559382]),\n",
       " array([ 0.49858396,  0.49691332,  0.49556723, ...,  0.49535101,\n",
       "         0.4951909 ,  0.49580626]),\n",
       " array([ 0.49865592,  0.49700384,  0.49553606, ...,  0.49532224,\n",
       "         0.49516392,  0.49577243]),\n",
       " array([ 0.49861368,  0.49697975,  0.49552811, ...,  0.4954843 ,\n",
       "         0.49532772,  0.49592955]),\n",
       " array([ 0.49857954,  0.49709398,  0.4955275 , ...,  0.49548418,\n",
       "         0.49532929,  0.49592459]),\n",
       " array([ 0.49863441,  0.49716482,  0.49561519, ...,  0.49557233,\n",
       "         0.49541911,  0.496008  ]),\n",
       " array([ 0.49861878,  0.49716483,  0.49563168, ...,  0.49558928,\n",
       "         0.49543769,  0.49602032]),\n",
       " array([ 0.49861774,  0.49717909,  0.49566208, ...,  0.49562012,\n",
       "         0.49547013,  0.49604662]),\n",
       " array([ 0.49864372,  0.49722006,  0.49571885, ...,  0.49567732,\n",
       "         0.49552889,  0.49609939]),\n",
       " array([ 0.49883871,  0.49722997,  0.49574424, ...,  0.49570314,\n",
       "         0.49555624,  0.49632059]),\n",
       " array([ 0.49869747,  0.4972792 ,  0.49580863, ...,  0.49576795,\n",
       "         0.49562255,  0.4963791 ]),\n",
       " array([ 0.49892838,  0.49728825,  0.49583253, ...,  0.49579226,\n",
       "         0.49564833,  0.49639724]),\n",
       " array([ 0.49896462,  0.49734089,  0.49589972, ...,  0.49573186,\n",
       "         0.49571736,  0.49633079]),\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('object') and format specifier ('%d, %.2f')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Programming\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-a8dc1eab7d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mYte\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AdaBoost/Y_submitTEST.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d, %.2f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID,Prob1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Programming\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1256\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0;32m   1257\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%d, %.2f')"
     ]
    }
   ],
   "source": [
    "Yte = np.vstack((np.arange(Xte.shape[0]), my_array)).T\n",
    "np.savetxt('AdaBoost/Y_submitTEST.txt', Yte, '%d, %.2f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724598604147\n",
      "0.726019655098\n"
     ]
    }
   ],
   "source": [
    "print(ensemble.predictSoft(Xte))\n",
    "ensemble_train_auc = (bt.auc(Xtr, Ytr) + linear.auc(XtrSP, Ytr) + metrics.roc_auc_score(ada_x_train, Ytr)) / 3\n",
    "ensemble_validation_auc = (bt.auc(Xva, Yva) + linear.auc(XvSP, Yva) + metrics.roc_auc_score(ada_x_val, Yva)) / 3\n",
    "print(ensemble_train_auc)\n",
    "print(ensemble_validation_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
